# -*- coding: utf-8 -*-
"""
B∆∞·ªõc 9 ‚Äî Gold Layer: LLM h·∫≠u ki·ªÉm (S·ª≠ d·ª•ng Qwen)
üéØ M·ª•c ti√™u: LLM gi√∫p vi·∫øt l·∫°i m√¥ t·∫£ ng·∫Øn g·ªçn, g·∫Øn nh√£n giao d·ªãch ch√≠nh x√°c.
üì• ƒê·∫ßu v√†o:
    - silver_candidates.csv (t·ª´ B∆∞·ªõc 8)
    - bank_stmt.csv, gl_entries.csv (ƒë·ªÉ tra c·ª©u th√¥ng tin g·ªëc)
‚öôÔ∏è X·ª≠ l√Ω:
    - D√πng m√¥ h√¨nh Qwen2.5-7B-Instruct ƒë·ªÉ ph√¢n t√≠ch
    - Chu·∫©n h√≥a lo·∫°i giao d·ªãch (TUITION, FEE, ADJUSTMENT)
    - T·∫°o explanation d·∫°ng JSON
üì§ ƒê·∫ßu ra: gold_layer_output.json
"""

import pandas as pd
import json
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

# === C√ÄI ƒê·∫∂T C·∫¶N THI·∫æT ===
# Ch·∫°y l·ªánh n√†y trong terminal:
# pip install google-generativeai pandas tqdm

# === THAM S·ªê ===
MODEL_NAME = "Qwen/Qwen1.5-7B-Chat"  # Ho·∫∑c ƒë∆∞·ªùng d·∫´n ƒë·∫øn model local
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 1  # S·ªë l∆∞·ª£ng c·∫∑p x·ª≠ l√Ω m·ªói l·∫ßn
MAX_NEW_TOKENS = 512  # ƒê·ªô d√†i t·ªëi ƒëa c·ªßa c√¢u tr·∫£ l·ªùi

# === ƒê∆Ø·ªúNG D·∫™N ===
script_dir = Path(__file__).resolve().parent
root_dir = script_dir.parent
data_dir = root_dir / "data"
output_dir = root_dir / "output"

# Input files
IN_SILVER = output_dir / "silver_candidates.csv"
IN_BANK = data_dir / "bank_stmt.csv"
IN_GL = data_dir / "gl_entries.csv"



# Output file
OUT_GOLD = output_dir / "gold_layer_output.json"

class TransactionValidator:
    def __init__(self, model_name=MODEL_NAME):
        """Kh·ªüi t·∫°o model v√† tokenizer"""
        print(f"‚úì ƒêang t·∫£i model {model_name}...")
        try:
            # Th·ª≠ t·∫£i t·ª´ cache local tr∆∞·ªõc
            cache_dir = root_dir / ".cache" / "models"
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            print("1. ƒêang t·∫£i tokenizer...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                trust_remote_code=True,
                cache_dir=cache_dir,
                resume_download=True,
                local_files_only=False,
                use_fast_tokenizer=True,
                padding_side='left'
            )
            
            print("2. ƒêang t·∫£i model...")
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                device_map="auto",
                trust_remote_code=True,
                cache_dir=cache_dir,
                resume_download=True,
                local_files_only=False,
                torch_dtype=torch.float16,  # D√πng FP16 ƒë·ªÉ gi·∫£m b·ªô nh·ªõ
                low_cpu_mem_usage=True
            )
            
            print("3. Chuy·ªÉn model sang ch·∫ø ƒë·ªô eval...")
            self.model.eval()
            
        except Exception as e:
            print(f"\n‚ùå L·ªói t·∫£i model: {str(e)}")
            print("\nG·ª£i √Ω kh·∫Øc ph·ª•c:")
            print("1. Ki·ªÉm tra k·∫øt n·ªëi internet")
            print("2. Th·ª≠ t·∫£i l·∫°i n·∫øu b·ªã gi√°n ƒëo·∫°n")
            print("3. Ki·ªÉm tra dung l∆∞·ª£ng ·ªï ƒëƒ©a v√† b·ªô nh·ªõ")
            print("4. N·∫øu c√≥ s·∫µn model local, ƒë·∫∑t ƒë∆∞·ªùng d·∫´n v√†o MODEL_NAME")
            raise e

    def prepare_prompt(self, bank_info, gl_info):
        """Chu·∫©n b·ªã prompt cho LLM"""
        # Format amounts safely
        try:
            bank_amount = f"{float(bank_info.get('amount', 0)):,.0f}"
            gl_amount = f"{float(gl_info.get('amount', 0)):,.0f}"
        except:
            bank_amount = "0"
            gl_amount = "0"

        prompt = f"""Analyze these transactions and determine if they match:

Bank Transaction:
- Reference: {str(bank_info.get('ref', ''))}
- Amount: {bank_amount} VND
- Description: {str(bank_info.get('desc', ''))}
- Date: {str(bank_info.get('date', ''))}

GL Entry:
- Document: {str(gl_info.get('doc_no', ''))}
- Amount: {gl_amount} VND
- Partner: {str(gl_info.get('partner', ''))}
- Date: {str(gl_info.get('date', ''))}

Classify as:
- TUITION: Student tuition payments
- FEE: Other service fees and charges 
- ADJUSTMENT: Balance corrections and adjustments

Return only a valid JSON object with these exact fields:
- bank_ref: The bank transaction reference
- gl_doc: The GL document number  
- match_type: One of "TUITION", "FEE", or "ADJUSTMENT"
- explanation: Brief reason why they match

Response must be valid JSON only, no other text."""

        return prompt
        
    @torch.inference_mode()
    def analyze_transaction(self, bank_info, gl_info):
        """Analyze a transaction pair using LLM"""
        try:
            # Prepare prompt
            prompt = self.prepare_prompt(bank_info, gl_info)
            
            # Tokenize v·ªõi streaming
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=2048
            ).to(DEVICE)
            
            # Generate v·ªõi streaming
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=MAX_NEW_TOKENS,
                num_return_sequences=1,
                do_sample=False,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
                early_stopping=True,
                num_beams=1,
                length_penalty=1.0
            )
            
            # Decode response
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
            
            # Extract JSON more carefully
            try:
                # T√¨m v√† chu·∫©n h√≥a ph·∫ßn JSON
                start_idx = response.find("{")
                end_idx = response.rfind("}") + 1
                if start_idx == -1 or end_idx == 0:
                    print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y JSON trong response: {response[:100]}...")
                    return None
                    
                json_str = response[start_idx:end_idx]
                # ƒê·∫£m b·∫£o JSON h·ª£p l·ªá
                result = json.loads(json_str)
                
                # Ki·ªÉm tra c√°c tr∆∞·ªùng b·∫Øt bu·ªôc
                required_fields = ['bank_ref', 'gl_doc', 'match_type', 'explanation']
                if not all(field in result for field in required_fields):
                    missing = [f for f in required_fields if f not in result]
                    print(f"‚ö†Ô∏è Thi·∫øu c√°c tr∆∞·ªùng JSON: {missing}")
                    return None
                    
                # Ki·ªÉm tra match_type h·ª£p l·ªá
                valid_types = ['TUITION', 'FEE', 'ADJUSTMENT']
                if result['match_type'] not in valid_types:
                    print(f"‚ö†Ô∏è match_type kh√¥ng h·ª£p l·ªá: {result['match_type']}")
                    return None
                    
                return result
                
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è L·ªói JSON kh√¥ng h·ª£p l·ªá: {str(e)}")
                print(f"Response: {response[:100]}...")
                return None
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch giao d·ªãch: {str(e)}")
            return None

def main():
    print("\n=== B∆Ø·ªöC 9: GOLD LAYER - LLM H·∫¨U KI·ªÇM ===")

    # 1. Ki·ªÉm tra files
    required_files = [IN_SILVER, IN_BANK, IN_GL]
    for file_path in required_files:
        if not file_path.exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}")
            return
            
    # 2. ƒê·ªçc d·ªØ li·ªáu
    try:
        print("‚úì ƒêang ƒë·ªçc d·ªØ li·ªáu...")
        silver_df = pd.read_csv(IN_SILVER)
        bank_df = pd.read_csv(IN_BANK)
        gl_df = pd.read_csv(IN_GL)
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        bank_df['ref'] = bank_df['ref'].astype(str)
        gl_df['doc_no'] = gl_df['doc_no'].astype(str)
        
        print(f"‚úì ƒê√£ ƒë·ªçc:")
        print(f"  - {len(silver_df):,} c·∫∑p t·ª´ silver_candidates.csv")
        print(f"  - {len(bank_df):,} giao d·ªãch t·ª´ bank_stmt.csv")
        print(f"  - {len(gl_df):,} b√∫t to√°n t·ª´ gl_entries.csv")
        
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc d·ªØ li·ªáu: {str(e)}")
        return
        
    # 3. Kh·ªüi t·∫°o validator
    try:
        validator = TransactionValidator()
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o model: {str(e)}")
        return
        
    # 4. Ph√¢n t√≠ch giao d·ªãch
    print("\n‚úì B·∫Øt ƒë·∫ßu ph√¢n t√≠ch giao d·ªãch...")
    gold_results = []
    
    # Ch·ªâ l·∫•y c√°c c·∫∑p c√≥ ƒëi·ªÉm cao nh·∫•t cho m·ªói bank_ref
    top_matches = silver_df.loc[silver_df.groupby('bank_ref')['f_text'].idxmax()]
    
    for _, row in tqdm(top_matches.iterrows(), total=len(top_matches)):
        try:
            bank_ref = str(row['bank_ref'])
            gl_doc = str(row['gl_doc'])
            
            # L·∫•y th√¥ng tin chi ti·∫øt
            bank_info = bank_df[bank_df['ref'] == bank_ref].iloc[0].to_dict()
            gl_info = gl_df[gl_df['doc_no'] == gl_doc].iloc[0].to_dict()
            
            # Ph√¢n t√≠ch b·∫±ng LLM
            analysis = validator.analyze_transaction(bank_info, gl_info)
            
            if analysis and all(k in analysis for k in ['bank_ref', 'gl_doc', 'match_type', 'explanation']):
                gold_results.append(analysis)
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω c·∫∑p {bank_ref}-{gl_doc}: {str(e)}")
            continue
            
    # 5. L∆∞u k·∫øt qu·∫£
    if not gold_results:
        print("\n‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch n√†o ƒë·ªÉ l∆∞u.")
        return
        
    try:
        # L∆∞u file JSON
        with open(OUT_GOLD, 'w', encoding='utf-8') as f:
            json.dump(gold_results, f, ensure_ascii=False, indent=2)
            
        print(f"\n‚úì ƒê√£ l∆∞u {len(gold_results):,} k·∫øt qu·∫£ v√†o {OUT_GOLD}")
        
        # Th·ªëng k√™ ph√¢n lo·∫°i
        results_df = pd.DataFrame(gold_results)
        print("\n=== TH·ªêNG K√ä PH√ÇN LO·∫†I ===")
        print(results_df['match_type'].value_counts())
        
        # In m·∫´u k·∫øt qu·∫£
        print("\n=== M·∫™U K·∫æT QU·∫¢ ===")
        print(json.dumps(gold_results[0], ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u k·∫øt qu·∫£: {str(e)}")
        return

if __name__ == '__main__':
    main()