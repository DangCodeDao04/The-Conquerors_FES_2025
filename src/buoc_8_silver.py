# -*- coding: utf-8 -*-
"""
BÆ°á»›c 8 â€” Silver Layer: Hybrid Text (BM25 + Embedding)
ğŸ¯ Má»¥c tiÃªu: TÄƒng kháº£ nÄƒng báº¯t cÃ¡c mÃ´ táº£ sai chÃ­nh táº£ hoáº·c viáº¿t khÃ¡c.
ğŸ“¥ Äáº§u vÃ o:
    - bank_stmt.csv (Ä‘á»ƒ láº¥y text mÃ´ táº£)
    - gl_entries.csv (Ä‘á»ƒ láº¥y text Ä‘á»‘i tÃ¡c)
    - adjusted_pairs.csv (Ä‘á»ƒ biáº¿t cÃ¡c cáº·p ÄÃƒ KHá»šP)
âš™ï¸ Xá»­ lÃ½:
    - TÃ­nh Ä‘iá»ƒm BM25 (keyword matching)
    - TÃ­nh Ä‘iá»ƒm Embedding (semantic matching)
    - Káº¿t há»£p: f_text = 0.5 * BM25_norm + 0.5 * Embedding_norm
    - LÆ°u top-3 á»©ng viÃªn.
ğŸ“¤ Äáº§u ra: silver_candidates.csv
"""

import pandas as pd
import numpy as np
from pathlib import Path
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer, util
from sklearn.preprocessing import MinMaxScaler
import warnings

warnings.filterwarnings('ignore')

# === CÃ€I Äáº¶T Cáº¦N THIáº¾T ===
# Cáº§n cÃ i Ä‘áº·t 2 thÆ° viá»‡n nÃ y trÆ°á»›c khi cháº¡y:
# pip install rank_bm25
# pip install sentence-transformers

# === THAM Sá» ===
MODEL_NAME = 'intfloat/multilingual-e5-small'  # Hoáº·c 'BAAI/bge-m3'
TOP_K = 3                # LÆ°u top-3 á»©ng viÃªn
HYBRID_WEIGHT_BM25 = 0.5 # Trá»ng sá»‘ cho BM25
HYBRID_WEIGHT_EMBED = 0.5 # Trá»ng sá»‘ cho Embedding

MIN_SCORE_THRESHOLD = 0.3 # NgÆ°á»¡ng Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ lÆ°u káº¿t quáº£

# === ÄÆ¯á»œNG DáºªN ===
script_dir = Path(__file__).resolve().parent
root_dir = script_dir.parent
data_dir = root_dir / "data"
output_dir = root_dir / "output"

# Input files
IN_BANK = data_dir / "bank_stmt.csv"
IN_GL = data_dir / "gl_entries.csv"
IN_ADJUSTED_PAIRS = output_dir / "adjusted_pairs.csv" # Äáº§u ra tá»« BÆ°á»›c 7

# Output file
OUT_SILVER = output_dir / "silver_candidates.csv"

def load_unmatched_data(bank_path, gl_path, adjusted_path):
    """
    Táº£i dá»¯ liá»‡u bank vÃ  GL, sau Ä‘Ã³ lá»c ra nhá»¯ng
    dÃ²ng chÆ°a Ä‘Æ°á»£c khá»›p á»Ÿ BÆ°á»›c 7.
    """
    bank_df = pd.read_csv(bank_path)
    gl_df = pd.read_csv(gl_path)
    adjusted_df = pd.read_csv(adjusted_path)

    # Lá»c cÃ¡c cáº·p Ä‘Ã£ review hoáº·c matched trong adjusted_pairs
    reviewed_pairs = adjusted_df[
        adjusted_df['match_status'].isin(['Review', 'Matched'])
    ][['bank_ref', 'gl_doc']]

    # Láº¥y danh sÃ¡ch cÃ¡c ref vÃ  doc Ä‘Ã£ khá»›p
    matched_bank_refs = reviewed_pairs['bank_ref'].unique()
    matched_gl_docs = reviewed_pairs['gl_doc'].unique()

    # Lá»c ra nhá»¯ng dÃ²ng chÆ°a khá»›p
    bank_df = bank_df.copy()
    gl_df = gl_df.copy()
    
    # Map ref Ä‘á»ƒ khá»›p vá»›i adjusted_pairs
    bank_df['ref'] = bank_df['ref'].astype(str)
    gl_df['doc_no'] = gl_df['doc_no'].astype(str)
    
    unmatched_bank = bank_df[~bank_df['ref'].isin(matched_bank_refs)].copy()
    unmatched_gl = gl_df[~gl_df['doc_no'].isin(matched_gl_docs)].copy()

    # Chuáº©n bá»‹ text: bank dÃ¹ng 'desc', GL dÃ¹ng 'partner'
    # .fillna('') Ä‘á»ƒ xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ NaN/trá»‘ng
    unmatched_bank['text'] = unmatched_bank['desc'].fillna('')
    unmatched_bank['desc'] = unmatched_bank['desc'].fillna('')  # Giá»¯ láº¡i desc gá»‘c
    unmatched_gl['text'] = unmatched_gl['partner'].fillna('')
    unmatched_gl['partner'] = unmatched_gl['partner'].fillna('')  # Giá»¯ láº¡i partner gá»‘c
    
    # Chá»‰ láº¥y cÃ¡c cá»™t cáº§n thiáº¿t
    unmatched_bank = unmatched_bank[['ref', 'text', 'desc']]
    unmatched_gl = unmatched_gl[['doc_no', 'text', 'partner']]

    return unmatched_bank, unmatched_gl

def preprocess_text(text):
    """Tiá»n xá»­ lÃ½ text trÆ°á»›c khi tÃ­nh toÃ¡n"""
    text = str(text).lower()
    # CÃ³ thá»ƒ thÃªm cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ khÃ¡c nhÆ°:
    # - Loáº¡i bá» dáº¥u cÃ¢u
    # - Chuáº©n hÃ³a unicode
    # - Loáº¡i bá» stopwords
    return text

def get_bm25_scores(queries, corpus):
    """TÃ­nh Ä‘iá»ƒm BM25 vá»›i tiá»n xá»­ lÃ½ cáº£i tiáº¿n"""
    print("... Äang tÃ­nh Ä‘iá»ƒm BM25 ...")
    
    # Tiá»n xá»­ lÃ½
    processed_corpus = [preprocess_text(doc) for doc in corpus]
    processed_queries = [preprocess_text(q) for q in queries]
    
    # Tokenize
    tokenized_corpus = [doc.split() for doc in processed_corpus]
    tokenized_queries = [q.split() for q in processed_queries]
    
    # Khá»Ÿi táº¡o BM25
    bm25 = BM25Okapi(tokenized_corpus)
    
    # TÃ­nh Ä‘iá»ƒm
    bm25_scores = [bm25.get_scores(q) for q in tokenized_queries]
    scores = np.array(bm25_scores)
    
    # Chuáº©n hÃ³a vá» [0,1]
    max_scores = np.maximum(scores.max(axis=1, keepdims=True), 1e-6)
    normalized_scores = scores / max_scores
    
    return normalized_scores

def get_embedding_scores(model, queries, corpus):
    """TÃ­nh Ä‘iá»ƒm embedding similarity vá»›i caching"""
    print(f"... Äang tÃ­nh Embedding (sá»­ dá»¥ng {MODEL_NAME}) ...")
    
    # Tiá»n xá»­ lÃ½
    processed_queries = [preprocess_text(q) for q in queries]
    processed_corpus = [preprocess_text(doc) for doc in corpus]
    
    # TÃ­nh embeddings
    query_embeddings = model.encode(
        processed_queries,
        convert_to_tensor=True,
        show_progress_bar=True,
        batch_size=32  # TÄƒng tá»‘c Ä‘á»™ vá»›i batching
    )
    
    corpus_embeddings = model.encode(
        processed_corpus,
        convert_to_tensor=True,
        show_progress_bar=True,
        batch_size=32
    )
    
    # TÃ­nh cosine similarity
    similarities = util.cos_sim(query_embeddings, corpus_embeddings)
    return similarities.cpu().numpy()

def get_ground_truth_pairs(adjusted_path):
    """Äá»c cÃ¡c cáº·p Ä‘Ã£ khá»›p tá»« adjusted_pairs.csv Ä‘á»ƒ lÃ m ground truth"""
    df = pd.read_csv(adjusted_path)
    # Láº¥y cÃ¡c cáº·p cÃ³ status lÃ  Matched
    matched = df[df['match_status'] == 'Matched'][['bank_ref', 'gl_doc']]
    # Táº¡o dictionary Ä‘á»ƒ map bank_ref -> gl_doc
    truth_dict = dict(zip(matched['bank_ref'], matched['gl_doc']))
    return truth_dict

def calculate_recall_at_k(bank_ref, predictions, truth_dict, k=3):
    """TÃ­nh Recall@K cho má»™t query dá»±a trÃªn ground truth"""
    if bank_ref not in truth_dict:
        return 0.0  # KhÃ´ng cÃ³ trong ground truth
    correct_gl = truth_dict[bank_ref]
    if correct_gl in predictions[:k]:
        return 1.0
    return 0.0

def main():
    print("\n=== BÆ¯á»šC 8: SILVER LAYER - HYBRID TEXT MATCHING ===")

    # 1. Kiá»ƒm tra vÃ  táº£i dá»¯ liá»‡u
    required_files = [IN_BANK, IN_GL, IN_ADJUSTED_PAIRS]
    for file_path in required_files:
        if not file_path.exists():
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {file_path}")
            return
            
    print("âœ“ Äang táº£i dá»¯ liá»‡u...")
    try:
        bank_queries_df, gl_corpus_df = load_unmatched_data(IN_BANK, IN_GL, IN_ADJUSTED_PAIRS)
        
        if bank_queries_df.empty or gl_corpus_df.empty:
            print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u bank hoáº·c GL chÆ°a khá»›p Ä‘á»ƒ xá»­ lÃ½.")
            return

        print(f"âœ“ Dá»¯ liá»‡u chÆ°a khá»›p: {len(bank_queries_df):,} bank vs {len(gl_corpus_df):,} GL")
        
        queries_list = bank_queries_df['text'].tolist()
        corpus_list = gl_corpus_df['text'].tolist()

    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {str(e)}")
        return

    # 2. Táº£i mÃ´ hÃ¬nh embedding
    print(f"\nâœ“ Äang táº£i mÃ´ hÃ¬nh {MODEL_NAME}...")
    try:
        model = SentenceTransformer(MODEL_NAME)
    except Exception as e:
        print(f"âŒ Lá»—i táº£i mÃ´ hÃ¬nh: {str(e)}")
        print("Hint: Kiá»ƒm tra káº¿t ná»‘i máº¡ng hoáº·c cÃ i Ä‘áº·t thÆ° viá»‡n.")
        return

    # 3. TÃ­nh toÃ¡n Ä‘iá»ƒm BM25 vÃ  Embedding
    try:
        # TÃ­nh Ä‘iá»ƒm BM25 (Ä‘Ã£ chuáº©n hÃ³a)
        bm25_scores = get_bm25_scores(queries_list, corpus_list)
        
        # TÃ­nh Ä‘iá»ƒm Embedding (Ä‘Ã£ chuáº©n hÃ³a)
        embed_scores = get_embedding_scores(model, queries_list, corpus_list)
        
        # Káº¿t há»£p Ä‘iá»ƒm vá»›i trá»ng sá»‘
        hybrid_scores = (HYBRID_WEIGHT_BM25 * bm25_scores + 
                        HYBRID_WEIGHT_EMBED * embed_scores)
                        
    except Exception as e:
        print(f"âŒ Lá»—i tÃ­nh toÃ¡n Ä‘iá»ƒm: {str(e)}")
        return

    # 4. Táº£i ground truth vÃ  trÃ­ch xuáº¥t Top-K á»©ng viÃªn
    print("\nâœ“ Äang táº£i ground truth tá»« adjusted_pairs.csv...")
    truth_dict = get_ground_truth_pairs(IN_ADJUSTED_PAIRS)
    
    print(f"âœ“ Äang xá»­ lÃ½ {len(queries_list):,} queries...")
    results = []
    recalls = []
    
    for query_idx, scores in enumerate(hybrid_scores):
        bank_ref = str(bank_queries_df['ref'].iloc[query_idx])
        bank_desc = str(bank_queries_df['desc'].iloc[query_idx])
        
        # Láº¥y top-K theo Ä‘iá»ƒm
        top_k_indices = np.argsort(scores)[-TOP_K:][::-1]
        
        # Láº¥y danh sÃ¡ch GL docs cho query nÃ y
        gl_candidates = [str(gl_corpus_df['doc_no'].iloc[i]) for i in top_k_indices]
        
        # TÃ­nh Recall@K
        recall = calculate_recall_at_k(bank_ref, gl_candidates, truth_dict, TOP_K)
        recalls.append(recall)
        
        # LÆ°u káº¿t quáº£ cho tá»«ng á»©ng viÃªn
        for rank, idx in enumerate(top_k_indices):
            score = scores[idx]
            gl_partner = str(gl_corpus_df['partner'].iloc[idx])
            
            if score >= MIN_SCORE_THRESHOLD:  # Chá»‰ lÆ°u náº¿u vÆ°á»£t ngÆ°á»¡ng
                # TÃ­nh text similarity tá»« Ä‘iá»ƒm BM25 vÃ  embedding
                text_similarity = score  # ÄÃ£ lÃ  Ä‘iá»ƒm káº¿t há»£p giá»¯a BM25 vÃ  embedding
                
                # XÃ¡c Ä‘á»‹nh reason_flag
                reason_flag = []
                if score >= 0.8:
                    reason_flag.append("HIGH_SIMILARITY")
                if bm25_scores[query_idx][idx] >= 0.7:
                    reason_flag.append("STRONG_TEXT_MATCH")
                if embed_scores[query_idx][idx] >= 0.7:
                    reason_flag.append("STRONG_SEMANTIC_MATCH")
                if not reason_flag:
                    reason_flag.append("POTENTIAL_MATCH")
                    
                results.append({
                    'bank_ref': bank_ref,
                    'gl_doc': str(gl_corpus_df['doc_no'].iloc[idx]),
                    'partner': gl_partner,
                    'text_similarity': round(text_similarity, 4),
                    'reason_flag': "|".join(reason_flag),
                    'f_text': round(score, 4),
                    'Recall@3': recall,
                    'Rank': rank + 1,
                    'in_ground_truth': bank_ref in truth_dict
                })

    # 5. Táº¡o DataFrame káº¿t quáº£
    if not results:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y á»©ng viÃªn nÃ o vÆ°á»£t ngÆ°á»¡ng Ä‘iá»ƒm.")
        return

    results_df = pd.DataFrame(results)
    
    # Sáº¯p xáº¿p theo bank_ref vÃ  Ä‘iá»ƒm sá»‘
    results_df = results_df.sort_values(
        ['bank_ref', 'f_text'], 
        ascending=[True, False]
    )
    
    # 6. LÆ°u káº¿t quáº£ vÃ  in thá»‘ng kÃª
    results_df.to_csv(OUT_SILVER, index=False)
    
    # TÃ­nh cÃ¡c thá»‘ng kÃª
    ground_truth_count = sum(1 for ref in bank_queries_df['ref'] if ref in truth_dict)
    
    print("\n=== THá»NG KÃŠ ===")
    print(f"âœ“ Tá»•ng sá»‘ cáº·p á»©ng viÃªn: {len(results_df):,}")
    print(f"âœ“ Sá»‘ lÆ°á»£ng bank refs: {results_df['bank_ref'].nunique():,}")
    print(f"âœ“ Äiá»ƒm trung bÃ¬nh: {results_df['f_text'].mean():.4f}")
    print(f"âœ“ Recall@{TOP_K}: {np.mean(recalls):.2%}")
    print(f"âœ“ Trong ground truth: {sum(results_df['in_ground_truth']):,}/{ground_truth_count:,}")
    
    print("\n=== MáºªU Káº¾T QUáº¢ ===")
    print(results_df[['bank_ref', 'gl_doc', 'partner', 'text_similarity', 'reason_flag', 'f_text', 'Rank']]
          .head(5)
          .to_string(index=False))

if __name__ == '__main__':
    main()